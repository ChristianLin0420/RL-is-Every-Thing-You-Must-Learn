# Day 9: Curiosity & Intrinsic Rewards

## ğŸ¯ Goal
Study and implement curiosity-driven learning with intrinsic motivation.

## ğŸ“‹ Task
- Implement Intrinsic Curiosity Module (ICM) or empowerment-based exploration
- Test on environments with sparse external rewards
- Analyze forward vs inverse model predictions
- Compare with count-based exploration

## ğŸ”‘ Key Concepts
- **ICM**: Forward and inverse models for curiosity
- **Prediction Error**: Surprise as intrinsic reward signal
- **Empowerment**: Mutual information between actions and states
- **Feature Learning**: Learning representations for prediction

## ğŸ“š Learning Objectives
1. Understand curiosity as a learning signal
2. Implement forward and inverse dynamics models
3. Balance intrinsic and extrinsic rewards
4. Analyze learned feature representations

## ğŸ› ï¸ Implementation Guidelines
- Implement ICM with feature encoder
- Use prediction error as intrinsic reward
- Test on maze or exploration games
- Visualize learned features and predictions

## ğŸ“– Resources
- Curiosity-driven Exploration by Self-supervised Prediction (Pathak et al.)
- Variational Information Maximisation for Intrinsically Motivated RL (Houthooft et al.) 